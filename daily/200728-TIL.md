# 200728
# To Day I Learned..
- A. HackerRank Alogrithm (python)
  - 1.List Comprehensions
  - 2.Plus Minus
- B. Deeplearning
  - 1.2-06. Optimization _ Training (Keras)
  - 2.2-07~8. Optimization _ Training (Expert)(1)
  - 3.2-07~8. Optimization _ Training (Expert)(2)

## A. HackerRank Alogrithm (python)
### A-1. List Comprehensions
  - #### x,y,z 보다 작은 수로 이루어진 list들을 만들기 
  - #### [x,y,z]의 원소들로 이루어진 [i,j,k]의 리스트들을 만들고 원소의 합이 n보다 작은것만 출력하게 하는 문제
  - ```python
    if __name__ == '__main__':
    x = int(input())
    y = int(input())
    z = int(input())
    n = int(input())

    total_ls = []
    ls = []
    for i in range(x+1):
        for j in range(y+1):
            for k in range(z+1):
                ls.append(i)
                ls.append(j)
                ls.append(k)
                if sum(ls) != n:
                    total_ls.append(ls)
                ls = []
    print(total_ls)```

### A-2. Plus Minus
  - #### arr의 양수, 음수, 0을 확인하고 전체 갯수에서 몇개나 있는지 소수점으로 표현
  - #### 어렵지 않았고, fillter와 lambda 함수를 이용하여 양수, 음수, 0을 판독하는 코드를 작성함
  - ```python
    import math
    import os
    import random
    import re
    import sys

    # Complete the plusMinus function below.
    def plusMinus(arr):
        print(round(len(list(filter(lambda x : x > 0, arr))) / len(arr), 6))
        print(round(len(list(filter(lambda x : x < 0, arr))) / len(arr), 6))
        print(round(len(list(filter(lambda x : x == 0, arr))) / len(arr), 6))

    if __name__ == '__main__':
        n = int(input())

        arr = list(map(int, input().rstrip().split()))

        plusMinus(arr)```

## B. Deeplearning
### B-1. Part2-06. Optimization _ Training (Keras)
  - #### Deeplearning의 학습과정
    - Data -> model -> logit -> Optm -> loss -> model or Result
    - Model : 생성 혹은 업데이트한 모델
    - logit : 입력된 데이터를 가지고 모델로 예측
    - Loss : 손실함수를 계산(작아지게 만들기)
    - Optm : 최적화, 이후 모델에 update 이 4가지를 반복한 뒤 Result를 냍음
  
  - #### Loss function
    - Loss function은 crossentropy로 구함
    - mnist는 class가 2개 이상이니 categorical
    - onehotencoding을 안했으니, sparse를 줌
    - Categorical vs Binary
      - class가 2개일때 Binary
      - class가 2개 이상일때는 Categorical
      ```python
      loss = 'binary_crossentropy'
      loss = 'categorical_crossentropy'

      # 원핫인코딩이 안됐을때
      tf.keras.losses.sparse_categorical_crossentropy

      # 원핫인코딩이 되어있을때
      tf.keras.losses.categorical_crossentropy

      # loss function 정의
      loss = tf.keras.losses.sparse_categorical_crossentropy
      ```
  - #### Metrics
    - 모델을 평가하는 방법
    ```python
    metrics = ['accuracy']

    # keras에서 바로 줄수있음
    tf.keras.metrics.Accuracy()
    tf.keras.metrics.Precision()
    tf.keras.metrics.Recall()

    # 아래처럼도 가능
    metrics = [tf.keras.metrics.Accuracy()]
    ```
  
  - #### Optimizer
    - Loss function을 찾기 위한 수리계획 문제 Adam, rmsprop, sgd 등이 있음.

  - #### Compile
    - 앞에서 설정한 Optimizer, loss function, metrics를 compilme하는 작업
    - 이것이 모델의 optimize 최적화임
    ```python
    # metrics는 list형태로 주어야함
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    ```
    
  - #### Prepare Dataset  
    - 학습에 사용할 데이터셋 준비
    - 차원수 늘리기
    ```python
    # 넘파이 사용
    np.expand_dims(train_x, -1).shape

    # tensorflow 사용
    train_x = tf.expand_dims(train_x, -1)

    # tensorflow 사용(2)
    train_x = train_x[..., tf.newaxis]
    test_x = test_x[..., tf.newaxis]

    # 차원수 확인

    train_x.shape, test_x.shape
    ```

    - Rescaling
      - 숫자가 0 ~ 255 라서 너무 크므로, 0과 1사이로 rescaling을 해주어 학습도를 높임
      ```python
      # 0과 1사이값으로 rescaling
      # train에 했으면 test에도 해야함
      train_x = train_x / 255.
      test_x = test_x / 255.
      ```
  - #### Training
    - 학습용 Hyperparameter 설정
    - epochs : 데이터를 몇번 볼지 정하는것 (1epochs는 전체 데이터를 1번 훑음)
    - batch_size : 한번의 batch마다 주는 데이터 샘플의 size
        - data = 2000, epochs = 20, batch_size = 500이라면 1 epochs는 데이터의 size가 500인 batch가 들어서 4번의 iteration을 하면 됨
    ```python
    num_epochs = 1
    batch_size = 32
    ```

    - model.fit : 생성 및 컴파일한 모델로 학습시키는 것
    - shuffle : 들어가는 데이터가 순서대로 안들어가게 셔플하는것(기본 옵션)
    - 왜인지는 모르겠지만 강의에 나온대로 sparse로 하면 자꾸 에러가 남.
    - 그래서 onehotencoding을 따로 해주고, model compile도 sparse_categorical에서 그냥 categorical로 바꿈
    ```python
    # 원핫 인코딩
    from tensorflow.keras.utils import to_categorical
    label_onehot = to_categorical(train_y, num_classes=10)
    label_onehot

    # 모델 학습
    model.fit(train_x, label_onehot,
          batch_size=batch_size,
          epochs=num_epochs)
    ```
### B-2. 2-07~8. Optimization _ Training (Expert)(1)
  - #### 앞에서 배운 내용을 공식 홈페이지에서 설명하는 Expert 버전으로 학습
  - #### tf.data를 사용
  ```python
  # 데이터를 iteration을 하면 안에 데이터가 1개씩 나오게 되는것
  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
  # 데이터 섞어줌
  train_ds = train_ds.shuffle(1000)
  # 배치사이즈 설정
  train_ds = train_ds.batch(32)

  # test도 같이 설정
  test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))
  test_ds = test_ds.batch(32)
  ```

  - #### 시각화 해보기
    - train_ds에 x와 y가 모두 있으므로 시각화를 진행해봄
    ```python
    for image, label in train_ds.take(2):
      plt.title(str(label[0]))
      plt.imshow(image[0, :, :, 0], 'gray')
      plt.grid(False)
      plt.show()
    ```

  - #### Training (Keras)
    - Keras로 학습을 하게 되면 기존과 같지만, train_ds는 generator라서 그대로 넣을 수 있음
    ```python
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
    model.fit(train_ds, epochs = 1)
    ```

  - #### Optimization(export)
    - Loss function 설정
    - Optimizer 설정
    ```python
    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
    optimizer = tf.keras.optimizers.Adam()
    ```
    - Loss Function를 담을 곳
    - 에포크마다 loss function의 평균값을 낸것을 담음
    - Metrics
    ```python
    train_loss = tf.keras.metrics.Mean(name = 'train_loss')
    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')

    test_loss = tf.keras.metrics.Mean(name = 'test_loss')
    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')
    ```

### B-3. 2-07~8. Optimization _ Training (Expert)(2)
  - #### Trianing
    - 실제 함수를 만들어서 trian, test를 진행하게 해보기
    - @tf.function - 기존 session 열었던 것처럼 바로 작동 안 하고, 그래프만 만들고 학습이 시작되면 돌아가도록 함
    ```python
    # train mode
    @tf.function
    def train_step(images, labels):
        with tf.GradientTape() as tape:
            predictions = model(images)
            loss = loss_object(labels, predictions)
            
        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        
        train_loss(loss)
        train_accuracy(labels, predictions)

    # test mode
    @tf.function
    def test_step(images, labels):
        predictions = model(images)
        t_loss = loss_object(labels, predictions)
        
        test_loss(t_loss)
        test_accuracy(labels, predictions)

    # for문으로 작동하게 epoch 넣기
    for epoch in range(2):
        for images, labels in train_ds:
            train_step(images, labels)
            
        for test_images, test_labels in test_ds:
            test_step(test_images, test_labels)
            
        template = 'Epoch : {}, Loss : {}, Accuracy : {}, Test Loss : {}, Test Accuracy : {}'
        print(template.format(epoch+1, 
                              train_loss.result(), train_accuracy.result() * 100,
                              test_loss.result(),
                              test_accuracy.result() * 100))
    ```
    - Epoch : 1, Loss : 0.101015105843544, Accuracy : 96.91166687011719, Test Loss : 0.03713757544755936, Test Accuracy : 98.68999481201172
    - Epoch : 2, Loss : 0.06793100386857986, Accuracy : 97.92916870117188, Test Loss : 0.03146180510520935, Test Accuracy : 99.0050048828125
    - 실행하면 위와 같은  accuracy, loss가 프린트 됨.