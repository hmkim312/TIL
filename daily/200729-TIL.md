# 200729
# To Day I Learned..
- A. HackerRank Alogrithm (python)
  - 1.Mini-Max Sum
  - 2.Loops
  - 3.Nested Lists
  - 4.Print Function
  - 5.Write a function
- B. Deeplearning
  - 1.2-09. Evaluating _ Predicting
  - 2.2-10. PyTorch 기초

## A. HackerRank Alogrithm (python)
### A-1. Mini-Max Sum
  - #### 5개의 원소로 이루어진 배열 arr이 주어졌을때 4개를 더해서 가장 작은수와 가장 큰수를 구하는것
  - #### 그냥 5개를 모두 더한뒤 가장 큰 수는 배열 중 가장 작은 수를 뺀것이고 가장 작은 수는 배열중 가장 큰수를 빼면됨
  - #### 위의 내용을 코드로 작성하여 return 시키는 함수를 작성
  ```python
  #!/bin/python3

  import math
  import os
  import random
  import re
  import sys

  # Complete the miniMaxSum function below.
  def miniMaxSum(arr):
      total_arr = sum(arr)
      arr = sorted(arr)
      max_arr = total_arr - arr[0]
      min_arr = total_arr - arr[4]
      return print(min_arr, max_arr)

  if __name__ == '__main__':
      arr = list(map(int, input().rstrip().split()))

      miniMaxSum(arr)
  ```
### A-2. Loops
  - #### n이 주어지면 0부터 n까지의 리스트를 만들고, 해당 원소들의 제곱을 프린트하는 코드를 작성
  - #### 그냥 for문으로 돌리고, i는 제곱한것을 프린트하면된다. 매우 easy
  ```python
  if __name__ == '__main__':
  n = int(input())
  for i in range(n):
      print(i ** 2)
  ```
### A-3. Nested Lists
  - #### 학생과 점수가 주어졌을때 2번째로 낮은 점수의 학생 이름을 출력하기 (동점자가 있을경우 이름순으로 출력)
  - #### 전체 recodes를 담을 리스트를 생성 후, 입력받는 name과 score를 저장
  - #### 전체 recodes를 학생 이름순으로 정렬 (동점자가 있을 경우 이름순으로 출력하기 위해)
  - #### 전체 recodes에서 아래에서 2등 점수를 가져옴 (set을 하는 이유는 꼴등이 여러명일 경우가 있을수 있으므로)
      - [score for name, score in recodes] : recodes에서 이름과 점수로 분리 후 점수만 list에 저장
      - set[score for name, score in recodes] : list에 저장한것을 다시 set(중복제거)
      - sorted(list(set([score for name, score in recodes])))[1] : 중복제거된 집합을 다시 list로 바꾸고, 정렬시킨뒤 그중 2번째애만 저장
      - 위의 점수가 score가 같으면 name을 출력하게 함
  ```python
  recodes = []
  if __name__ == '__main__':
      for _ in range(int(input())):
          name = input()
          score = float(input())
          recodes.append([name, score])
      recodes = sorted(recodes)
      for name, socre in recodes:
          if socre == sorted(list(set([score for name, score in recodes])))[1]:
              print(name)
  ```

### A-4.Print Function
  - #### n이 주어지면 해당 1부터n까지 프린트하면됨
  - #### 기본 print 함수의 end = '\n'이 디폴트이기때문에 그냥 이것을 ''띄어쓰기 없는것으로 주면 옆으로 프린트가 됨
  ```python
  if __name__ == '__main__':
    n = int(input())
    for i in range(1, n+1):
        print(i, end='')
  ```

### A-5.Write a function
  - #### 윤년인지 확인하는 함수 작성
  - #### 윤년은 4년마다 한번씩 오지만, 100년단위로 끊어지면 (ex 1900)은 윤년이 아님.
  - #### 하지만 100년 단위 중에서 400년 마다 1번씩 윤년임
  - #### 아래의 조건들을 순차적으로 하나씩 필터링 하게 하는 함수를 만듬
      - year를 400으로 나누어 0이 되면 윤년
      - year를 100으로 나누어 0이 되면 윤년이 아님
      - year를 4로 나누어 0이되면 윤년
      - 위의 조건이 모두 맞지않으면 윤년이 아님
  ```python
  def is_leap(year):
    leap = False

    # Write your logic here
    if year % 400 == 0:
        leap = True

    elif year % 100 == 0:
        leap = False

    elif year % 4 == 0:
        leap = True

    return leap
  year = int(input())
  print(is_leap(year))
  ```
## B. Deeplearning
### B-1.2-09. Evaluating _ Predicting
  - #### TensorFlow : Evaluation & Prediction
    - 전날 생성한 model을 가지고 검증하고 예측하기
    ```python
    # 생성한 모델
    inputs = layers.Input(input_shape)
    net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)
    net = layers.Activation('relu')(net)
    net = layers.Conv2D(32, (3, 3), padding='SAME')(net)
    net = layers.Activation('relu')(net)
    net = layers.MaxPooling2D(pool_size=(2, 2))(net)
    net = layers.Dropout(0.5)(net)

    net = layers.Conv2D(64, (3, 3), padding='SAME')(net)
    net = layers.Activation('relu')(net)
    net = layers.Conv2D(64, (3, 3), padding='SAME')(net)
    net = layers.Activation('relu')(net)
    net = layers.MaxPooling2D(pool_size=(2, 2))(net)
    net = layers.Dropout(0.5)(net)

    net = layers.Flatten()(net)
    net = layers.Dense(512)(net)
    net = layers.Activation('relu')(net)
    net = layers.Dropout(0.5)(net)
    net = layers.Dense(num_classes)(net)
    net = layers.Activation('softmax')(net)

    model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')

    # 모델 컴파일
    # Model is the full model w/o custom layers
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    # 데이터 셋 불러오고, 리사이징, 스케일링
    (train_x, train_y), (test_x, test_y) = datasets.mnist.load_data()
    train_x = train_x[..., tf.newaxis]
    test_x = test_x[..., tf.newaxis]

    train_x = train_x / 255.
    test_x = test_x / 255.

    # 모델 학습
    num_epochs = 1
    batch_size = 64
    hist = model.fit(train_x, train_y, 
                 batch_size=batch_size, 
                 shuffle=True)

    # 저장한 로드를 확인 - 한 epoch당 1개의 로그가 나옴
    hist.history
    ```

  - #### Evaluating
    - 학습한 모델 확인
    ```python
    # 학습한 모델을 test 데이터로 확인
    # accuracy가 0.987나옴
    model.evaluate(test_x, test_y, batch_size = batch_size)
    ```
  - #### 결과 확인
    - 이미지 1개 불러와서 해당 이미지를 넣고 확인
    - 이미지를 넣고나면 softmax 함수에 따라 class 별로 해당 input data가 가질수 있는 확률값을 보여줌
    - np.argmax를 이용하여 해당 값의 class(index)를 확인하면 됨
    ```python
    test_image = test_x[0, :,:,0]

    # pred변수안에 10개의 class가 각각 얼마만큼의 확률을 가지는지에 대한값이 정해져있음
    pred = model.predict(test_image.reshape(1,28,28,1))
    
    # 10개의 class를 뱉음
    pred.shape

    # 가장 높은 값 확인은 np.argmax로 하면됨(예측한 값이됨)
    np.argmax(pred)
    ```  
  
  - #### Test Batch
    - batch로 한번에 test dataset 넣기
    - 이번엔 이미지 1개만 넣는게 아니라 test dataset 32개를 모델에 넣고 예측
    ```python
    test_batch = test_x[:32]
    test_batch.shape #(32, 28, 28, 1)
    ```

    - batch test dataset을 모델에 넣기
    ```python
    preds = model.predict(test_batch)
    preds.shape # (32,10)
    ```

    - 결과 확인
    ```python
    # argmax의 옵션 인자를 -1를 주면 전체 데이터 예측값을 보여줌
    # 아래는 총 32개에 대한 예측값을 보여주게됨
    np.argmax(preds, -1)
    ```

    - 이미지로 확인해보기
    ```python
    plt.imshow(test_batch[2, :, :, 0],'gray')
    plt.grid(False)
    plt.show()
    ```

### B-2.2-10. PyTorch 기초
  - #### pytorch 기초 사용법
    - pytorch는 numpy에 있는것들을 사용할수 있다.
    ```python
    # 연속된 숫자 불러오기 numpy
    np.arange(9)

    # 연속된 숫자 불러오기 torch 넘파이와 비슷
    torch.arange(9)

    # shape 확인
    torch.arange(9).shape

    # numpy array 타입 변환
    num = torch.arange(9)
    num.numpy()

    # reshape도 가능
    num.reshape(3,3)

    # 랜덤 3x3
    torch.rand((3,3))

    # 0행렬
    torch.zeros((3,3))

    # 1행렬
    ones = torch.ones((5,5))
    ones

    # 같은 모양을 가진 0행렬을 만드는것
    torch.zeros_like(ones)

    # size확인
    ones.size()
    ``` 

  - ### Operation
    - #### pytorch로 수학 연산
      - pytorch도 numpy 처럼 수학 연산이 가능하다
      ```python
      # 브로드캐스팅 가능
      num * 3

      # reshape
      num = num.reshape((3,3))
      num

      # tensor끼리의 연산
      num + num

      # add(모든원소에 값을 더함)
      torch.add(num, 10)

      # numpy array로 변환 가능
      result = torch.add(num, 10)
      result.numpy()
      ```

  - ### View
    - #### reshape와 같은 기능을 제공함
      - pytorch에는 view라는 기능이 있는데, reshape와 같음
      ```python
      # view와 reshape는 별 차이는 없음
      range_nums.view(-1)
      # tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])

      range_nums.view(1,9)
      # tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8]])
      ```
  - ### Slice and Index
    - #### pytorch의 slice와 index
      - numpy에서 제공하는 slice와 index를 pytorch에서도 사용가능
      ```python
      num[1]
      # tensor([3, 4, 5])

      num[1,1]
      # tensor(4)

      num[1:,1:]
      # tensor([[4, 5],
      #         [7, 8]])

      num[1:]
      # tensor([[3, 4, 5],
      #         [6, 7, 8]])
      ```
  
  - ### Complie
    - #### numpy를 torch tensor로 불러오기
      - torch.from_numpy(arr)을 사용하면 됨
      ```python
      # numpy array를 torch로 불러오기 -> torch.from_numpy()
      arr = np.array([1, 1, 1])
      arr_torch = torch.from_numpy(arr)
      arr_torch

      # float 타입으로 변환
      arr_torch.float()

      # gpu, cpu 설정
      device = 'cuda' if torch.cuda.is_available() else 'cpu'
      arr_torch.to(device)
      ```
  
  - ### AutoGrad
    - #### 기울기를 얻어서 학습이 되게 기울기를 주는것(?)
      - 솔직히 강의에서도 설명이 매우 빈약했고, 무슨소리인지 잘 이해가 안간다..
      ```python
      # x설정
      x = torch.ones(2,2, requires_grad = True)
      x

      # y설정
      y = x + 2
      y

      # 펑션 확인
      print(y.grad_fn)

      # z 추가
      z = y * y * 3
      out = z.mean()
      print(z, out)

      # 기울기 구하기
      out.backward()

      # x의 기울기
      x.grad

      print(x.requires_grad)
      print((x ** 2).requires_grad)

      # torch.no_grad()를 사용하면 기울기를 구하지 않게됨
      # 작동 속도가 빨라짐
      with torch.no_grad():
          print((x ** 2).requires_grad)

      ```

